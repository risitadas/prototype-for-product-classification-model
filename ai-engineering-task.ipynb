{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":102696,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":86096,"modelId":110339}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-27T22:15:16.777945Z","iopub.execute_input":"2024-08-27T22:15:16.779285Z","iopub.status.idle":"2024-08-27T22:15:16.814128Z","shell.execute_reply.started":"2024-08-27T22:15:16.779193Z","shell.execute_reply":"2024-08-27T22:15:16.812735Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/product-classification-model/keras/default/1/LICENSE\n/kaggle/input/product-classification-model/keras/default/1/README.md\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Your task is to develop a prototype machine learning model for classifying dummy products into predefined categories. To reduce implementation time, you are encouraged to utilize TensorFlow. The objective is to demonstrate your ability to quickly prototype a solution for product classification and basic machine learning principles.\n\n\n\nPlease use the following prerequisites below:\n\n- use Python 3.9 and above. \n\n- use TensorFlow.\n\n- use Pandas\n\n- use NumPy\n\n\n\nThe task requirements:\n\n1. Data Generation\n\n- Create a small dataset of dummy products with attributes such as name, description, price, and category. Aim for a manageable number of products and categories to facilitate quicker processing.\n\n2. Data Preprocessing\n\n- Perform basic data preprocessing steps, such as tokenization of text attributes and encoding of categorical attributes. \n\n3. Data Preprocessing\n\n- Develop a simple text classification model using TensorFlow and Python. Consider using a basic neural network or a pre-trained model for faster development.\n\n- Train the model using the generated dataset and evaluate its performance using basic evaluation metrics.\n\n4. Documentation\n\n- Provide brief documentation outlining the approach taken, including any assumptions made and limitations of the prototype.","metadata":{}},{"cell_type":"markdown","source":"A brief documentation outlining the approach below, including assumptions and limitations of the prototype :\n\nDocumentation :\n\nApproach :\n\n1. Data Generation : \n\nwe created a dummy dataset with 1000 products, each having a name, description, price and a category. The categories are as Electronics , Clothing, Books, and Home & Kitchen.\n    \n2. Data Preprocessing :\n        \ni. Text proprocessing : we used TensorFlow's Tokenizer to convert product descriptions into sequence of integers, which were then padded to ensure uniform length.\n\nii. Category encoding : we used sklearn's LabelEncoder to convert category labels into numerical values.\n        \n3. Model Development : \n        \ni. we created a simple newural network using TensorFlow's Keras API.\n\nii. the model architecture consists of an Embedding layer, a GlobalAveragePooling1D layer, and two Dense layers.\n\niii. we used sparse categorical crossentropy as the loss function and Adam as the optimizer.\n\niv. the model was trained for 10 epochs with a validation split of 0.2 .\n       \n4. Evaluation : \n\nwe evaluated the model on a test set (20% of the data) and reported the test accuracy.\n    \n5. Prediction : \n\nwe implemented a function to predict the category for a new product description.\n    \n    \n    \nAssumptions : \n1. the dummy data generated is representative of the real-world product data.\n2. the product descriptions contain sufficient information for category classification.\n3. the predefined categories are mutually exclusive and cover all possible product types.\n    \n    \nLimitations :\n1. **small dataset** : the model is being trained on a small and random generated dataset, which may not capture the complexicity of real-world product data.\n2. **simple model architecture** : the current model is basic and may not capture comples relationships in the data.\n3. **limited text preprocessing** : we used basic tokenization. \n4. **fixed number of categories**: the model is designed for a fixed set of categories and would need to be retrained to accomodate new categories.\n5. also **model assums each product belongs to only one category**.\n    \n    \nThe below prototype demonstrates a basic classification using machine learning. ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\n\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"Pandas version:\", pd.__version__)\nprint(\"NumPy version:\", np.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T22:15:16.817111Z","iopub.execute_input":"2024-08-27T22:15:16.817572Z","iopub.status.idle":"2024-08-27T22:15:16.830272Z","shell.execute_reply.started":"2024-08-27T22:15:16.817519Z","shell.execute_reply":"2024-08-27T22:15:16.827427Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"TensorFlow version: 2.16.1\nPandas version: 2.2.2\nNumPy version: 1.26.4\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Step 1 : Data Generation \n\ndef generate_dummy_data(n_samples=1000):\n    categories = ['Electronics', 'Clothing', 'Books', 'Home & Kitchen']\n    \n    data = {\n        'name': [f'Product {i}' for i in range(n_samples)],\n        'description': [f'This is a description for product {i}' for i in range(n_samples)],\n        'price': np.random.uniform(10, 1000, n_samples).round(2),\n        'category': np.random.choice(categories, n_samples)\n    }\n    \n    return pd.DataFrame(data)\n\n\n# Generating the dummy data\n\ndf = generate_dummy_data()\n\n# Printing a snippet of the generated data\n\nprint(\"Snippet of generated dummy data:\")\nprint(df.head())\nprint(\"\\nDataset shape:\", df.shape)\nprint(\"\\nCategory distribution:\")\nprint(df['category'].value_counts())\n\n# Step 2 : Data Preprocessing \n\n# Tokenize text\n\ntokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(df['description'])\nsequences = tokenizer.texts_to_sequences(df['description'])\npadded_sequences = pad_sequences(sequences, maxlen=100, padding='post', truncating='post')\n\n# Encode categories\n\nlabel_encoder = LabelEncoder()\nencoded_categories = label_encoder.fit_transform(df['category'])\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(padded_sequences, encoded_categories, test_size=0.2, random_state=42)\n\n# Step 3 : Model Development \n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=5000, output_dim=16, input_length=100),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')\n])\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Training the model\n\nhistory = model.fit(X_train, y_train, epochs=10, validation_split=0.2, batch_size=32)\n\n# Step 4 : Evaluation of the model\n\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test accuracy: {test_accuracy:.4f}\")\n\n# Step 5 : Prediction\n\ndef predict_category(description):\n    sequence = tokenizer.texts_to_sequences([description])\n    padded = pad_sequences(sequence, maxlen=100, padding='post', truncating='post')\n    prediction = model.predict(padded)\n    predicted_category = label_encoder.inverse_transform([np.argmax(prediction)])\n    return predicted_category[0]\n\n\n\n# example\n\nnew_product_description = \"A new smartphone with advanced features\"\npredicted_category = predict_category(new_product_description)\nprint(f\"Predicted category for '{new_product_description}': {predicted_category}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-27T22:15:16.833196Z","iopub.execute_input":"2024-08-27T22:15:16.834127Z","iopub.status.idle":"2024-08-27T22:15:19.834515Z","shell.execute_reply.started":"2024-08-27T22:15:16.834071Z","shell.execute_reply":"2024-08-27T22:15:19.833167Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Snippet of generated dummy data:\n        name                          description   price        category\n0  Product 0  This is a description for product 0   91.40        Clothing\n1  Product 1  This is a description for product 1  456.61     Electronics\n2  Product 2  This is a description for product 2  527.28  Home & Kitchen\n3  Product 3  This is a description for product 3   27.71     Electronics\n4  Product 4  This is a description for product 4  993.08     Electronics\n\nDataset shape: (1000, 4)\n\nCategory distribution:\ncategory\nClothing          267\nBooks             259\nHome & Kitchen    238\nElectronics       236\nName: count, dtype: int64\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.2540 - loss: 1.3870 - val_accuracy: 0.1813 - val_loss: 1.3943\nEpoch 2/10\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2469 - loss: 1.3832 - val_accuracy: 0.2812 - val_loss: 1.3906\nEpoch 3/10\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2649 - loss: 1.3850 - val_accuracy: 0.1813 - val_loss: 1.3939\nEpoch 4/10\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2870 - loss: 1.3833 - val_accuracy: 0.1813 - val_loss: 1.3948\nEpoch 5/10\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2794 - loss: 1.3841 - val_accuracy: 0.1813 - val_loss: 1.3940\nEpoch 6/10\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2892 - loss: 1.3842 - val_accuracy: 0.1813 - val_loss: 1.3953\nEpoch 7/10\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2296 - loss: 1.3903 - val_accuracy: 0.1813 - val_loss: 1.3912\nEpoch 8/10\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2715 - loss: 1.3846 - val_accuracy: 0.1813 - val_loss: 1.3973\nEpoch 9/10\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2936 - loss: 1.3799 - val_accuracy: 0.1813 - val_loss: 1.3977\nEpoch 10/10\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2718 - loss: 1.3838 - val_accuracy: 0.1813 - val_loss: 1.3926\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1485 - loss: 1.3975  \nTest accuracy: 0.1600\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\nPredicted category for 'A new smartphone with advanced features': Electronics\n","output_type":"stream"}]}]}